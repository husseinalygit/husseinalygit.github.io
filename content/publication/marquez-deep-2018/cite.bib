@article{marquez_deep_2018,
 abstract = {In this paper, we propose a novel approach for efficient training of deep neural networks in a bottom-up fashion using a layered structure. Our algorithm, which we refer to as deep cascade learning, is motivated by the cascade correlation approach of Fahlman and Lebiere, who introduced it in the context of perceptrons. We demonstrate our algorithm on networks of convolutional layers, though its applicability is more general. Such training of deep networks in a cascade directly circumvents the well-known vanishing gradient problem by ensuring that the output is always adjacent to the layer being trained. We present empirical evaluations comparing our deep cascade training with standard end-end training using back propagation of two convolutional neural network architectures on benchmark image classification tasks (CIFAR-10 and CIFAR-100). We then investigate the features learned by the approach and find that better, domain-specific, representations are learned in early layers when compared to what is learned in end-end training. This is partially attributable to the vanishing gradient problem that inhibits early layer filters to change significantly from their initial settings. While both networks perform similarly overall, recognition accuracy increases progressively with each added layer, with discriminative features learned in every stage of the network, whereas in end-end training, no such systematic feature representation was observed. We also show that such cascade training has significant computational and memory advantages over end-end training, and can be used as a pretraining algorithm to obtain a better performance.},
 author = {Marquez, Enrique S. and Hare, Jonathon S. and Niranjan, Mahesan},
 date = {2018-11},
 doi = {10.1109/TNNLS.2018.2805098},
 file = {Accepted Version:D\:\\Zetero\\storage\\NQHR7HC4\\Marquez et al. - 2018 - Deep Cascade Learning.pdf:application/pdf},
 issn = {2162-2388},
 journaltitle = {IEEE transactions on neural networks and learning systems},
 number = {11},
 pages = {5475--5485},
 pmid = {29993618},
 shortjournal = {IEEE Trans Neural Netw Learn Syst},
 title = {Deep Cascade Learning},
 volume = {29}
}
