@inproceedings{milli_model_2019,
 abstract = {We show through theory and experiment that gradient-based explanations of a model quickly reveal the model itself. Our results speak to a tension between the desire to keep a proprietary model secret and the ability to offer model explanations. On the theoretical side, we give an algorithm that provably learns a two-layer ReLU network in a setting where the algorithm may query the gradient of the model with respect to chosen inputs. The number of queries is independent of the dimension and nearly optimal in its dependence on the model size. Of interest not only from a learning-theoretic perspective, this result highlights the power of gradients rather than labels as a learning primitive. Complementing our theory, we give effective heuristics for reconstructing models from gradient explanations that are orders of magnitude more query-efficient than reconstruction attacks relying on prediction interfaces.},
 author = {Milli, Smitha and Schmidt, Ludwig and Dragan, Anca D. and Hardt, Moritz},
 booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
 date = {2019-01-29},
 doi = {10.1145/3287560.3287562},
 file = {Full Text PDF:D\:\\Zetero\\storage\\Q67EW9IZ\\Milli et al. - 2019 - Model Reconstruction from Model Explanations.pdf:application/pdf},
 isbn = {978-1-4503-6125-5},
 keywords = {machine learning, security, privacy, Explanations},
 location = {New York, NY, USA},
 pages = {1--9},
 publisher = {Association for Computing Machinery},
 series = {FAT* '19},
 title = {Model Reconstruction from Model Explanations},
 url = {https://dl.acm.org/doi/10.1145/3287560.3287562},
 urldate = {2023-05-11}
}
