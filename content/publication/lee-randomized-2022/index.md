---
title: A Randomized Link Transformer for Diverse Open-Domain Dialogue Generation
authors:
- Jing Yang Lee
- Kong Aik Lee
- Woon Seng Gan
date: '2022-05-01'
publishDate: '2023-11-24T10:39:00.414457Z'
publication_types:
- paper-conference
publication: '*Proceedings of the 4th Workshop on NLP for Conversational AI*'
doi: 10.18653/v1/2022.nlp4convai-1.1
abstract: A major issue in open-domain dialogue generation is the agent's tendency
  to generate repetitive and generic responses. The lack in response diversity has
  been addressed in recent years via the use of latent variable models, such as the
  Conditional Variational Auto-Encoder (CVAE), which typically involve learning a
  latent Gaussian distribution over potential response intents. However, due to latent
  variable collapse, training latent variable dialogue models are notoriously complex,
  requiring substantial modification to the standard training process and loss function.
  Other approaches proposed to improve response diversity also largely entail a significant
  increase in training complexity. Hence, this paper proposes a Randomized Link (RL)
  Transformer as an alternative to the latent variable models. The RL Transformer
  does not require any additional enhancements to the training process or loss function.
  Empirical results show that, when it comes to response diversity, the RL Transformer
  achieved comparable performance compared to latent variable models.
links:
- name: URL
  url: https://aclanthology.org/2022.nlp4convai-1.1
---
