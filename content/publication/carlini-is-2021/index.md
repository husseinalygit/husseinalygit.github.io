---
title: Is Private Learning Possible with Instance Encoding?
authors:
- Nicholas Carlini
- Samuel Deng
- Sanjam Garg
- Somesh Jha
- Saeed Mahloujifar
- Mohammad Mahmoody
- Abhradeep Thakurta
- Florian Tramèr
date: '2021-05-01'
publishDate: '2023-11-24T10:39:00.029345Z'
publication_types:
- paper-conference
publication: '*2021 IEEE Symposium on Security and Privacy (SP)*'
doi: 10.1109/SP40001.2021.00099
abstract: A private machine learning algorithm hides as much as possible about its
  training data while still preserving accuracy. In this work, we study whether a
  non-private learning algorithm can be made private by relying on an instance-encoding
  mechanism that modifies the training inputs before feeding them to a normal learner.
  We formalize both the notion of instance encoding and its privacy by providing two
  attack models. We first prove impossibility results for achieving a (stronger) model.
  Next, we demonstrate practical attacks in the second (weaker) attack model on InstaHide,
  a recent proposal by Huang, Song, Li and Arora [ICML’20] that aims to use instance
  encoding for privacy.
tags:
- Training
- Computational modeling
- Neural networks
- Privacy
- Training data
- Encoding
- Machine learning algorithms
---
