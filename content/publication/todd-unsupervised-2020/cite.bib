@inproceedings{todd_unsupervised_2020,
 abstract = {Each year, thousands of roughly 150-page parole hearing transcripts in California go unread because legal experts lack the time to review them. Yet, reviewing transcripts is the only means of public oversight in the parole process. To assist reviewers, we present a simple unsupervised technique for using language models (LMs) to identify procedural anomalies in long-form legal text. Our technique highlights unusual passages that suggest further review could be necessary. We utilize a contrastive perplexity score to identify passages, defined as the scaled difference between its perplexities from two LMs, one fine-tuned on the target (parole) domain, and another pre-trained on out-of-domain text to normalize for grammatical or syntactic anomalies. We present quantitative analysis of the results and note that our method has identified some important cases for review. We are also excited about potential applications in unsupervised anomaly detection, and present a brief analysis of results for detecting fake TripAdvisor reviews.},
 author = {Todd, Graham and Voss, Catalin and Hong, Jenny},
 booktitle = {Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science},
 date = {2020-11},
 doi = {10.18653/v1/2020.nlpcss-1.8},
 eventtitle = {NLP+CSS 2020},
 file = {Full Text PDF:D\:\\Zetero\\storage\\YZNCIFAD\\Todd et al. - 2020 - Unsupervised Anomaly Detection in Parole Hearings .pdf:application/pdf},
 location = {Online},
 pages = {66--71},
 publisher = {Association for Computational Linguistics},
 title = {Unsupervised Anomaly Detection in Parole Hearings using Language Models},
 url = {https://aclanthology.org/2020.nlpcss-1.8},
 urldate = {2023-03-08}
}
